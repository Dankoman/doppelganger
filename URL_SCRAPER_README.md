# URL-Baserad Scraper - KringgÃ¥ Blockerad Huvudsida

## ğŸ¯ ProblemlÃ¶sning

Den ursprungliga scrapern blockerades pÃ¥ huvudsidan (`all-porn-stars.php`) med 403 Forbidden-fel. Denna lÃ¶sning kringgÃ¥r problemet genom att:

1. **Extrahera alla profillÃ¤nkar** frÃ¥n en sparad HTML-fil
2. **Scrapa individuella profiler** direkt istÃ¤llet fÃ¶r huvudsidan
3. **AnvÃ¤nda samma anti-blocking system** fÃ¶r varje profil

## ğŸ“Š Statistik

- **6,360 profillÃ¤nkar** extraherade frÃ¥n HTML-fil
- **Individuella pornstar-profiler** (format: `/pornstars/a/aali_kali/index.php`)
- **Filtrerat bort navigeringslÃ¤nkar** automatiskt

## ğŸš€ AnvÃ¤ndning

### Snabbstart
```bash
# Bygg imagen
./run_scraper.sh build

# Testa med 5 profiler
./run_scraper.sh url_test

# Scrapa 100 profiler (rekommenderat fÃ¶r test)
./run_scraper.sh url_sample

# Scrapa alla 6,360 profiler
./run_scraper.sh url_run
```

### Debug och felsÃ¶kning
```bash
# Debug-lÃ¤ge fÃ¶r en profil
./run_scraper.sh url_debug

# Visa fÃ¶rsta 10 URL:er
head -10 profile_urls.txt

# Kontrollera antal URL:er
wc -l profile_urls.txt
```

## ğŸ“ Filer

### `profile_urls.txt`
InnehÃ¥ller alla 6,360 profillÃ¤nkar extraherade frÃ¥n HTML-filen:
```
https://www.mypornstarbook.net/pornstars/a/aali_kali/index.php
https://www.mypornstarbook.net/pornstars/a/aaliyah_grey/index.php
...
```

### `mpb_spider_from_urls.py`
Ny spider som:
- LÃ¤ser URL:er frÃ¥n `profile_urls.txt`
- Scrapar varje profil individuellt
- Extraherar namn, bilder och bio
- AnvÃ¤nder samma anti-blocking middleware

## ğŸ›¡ï¸ Anti-Blocking Funktioner

Samma avancerade anti-blocking system som v2.0:
- âœ… **12 realistiska User Agents** (Chrome, Firefox, Safari, Edge)
- âœ… **Avancerade headers** (sec-ch-ua, Sec-Fetch-*)
- âœ… **Adaptiv fÃ¶rdrÃ¶jning** (Ã¶kar vid 403-fel)
- âœ… **Exponential backoff** retry-logik
- âœ… **Brotli-komprimeringssstÃ¶d**
- âœ… **Intelligent referer-hantering**

## ğŸ“ˆ FÃ¶rdelar

### JÃ¤mfÃ¶rt med ursprunglig metod:
1. **KringgÃ¥r blockering** - Ingen Ã¥tkomst till blockerad huvudsida
2. **Mindre misstÃ¤nkt** - Inga upprepade requests till samma sida
3. **Mer effektivt** - Direkt Ã¥tkomst till mÃ¥lsidor
4. **Skalbart** - Kan hantera tusentals profiler
5. **Robust** - FortsÃ¤tter Ã¤ven om enskilda profiler misslyckas

### Prestanda:
- **Konservativa instÃ¤llningar**: 5s delay mellan requests
- **BegrÃ¤nsad samtidighet**: 1 concurrent request
- **Intelligent retry**: 6 fÃ¶rsÃ¶k med exponential backoff
- **Adaptiv timing**: Ã–kar delay vid problem

## ğŸ”§ Teknisk Implementation

### Docker-integration
```yaml
volumes:
  - ./profile_urls.txt:/app/profile_urls.txt:ro
```

### Spider-konfiguration
```python
class MpbFromUrlsSpider(scrapy.Spider):
    name = 'mpb_from_urls'
    
    def start_requests(self):
        with open('/app/profile_urls.txt', 'r') as f:
            urls = [line.strip() for line in f if line.strip()]
        
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)
```

## ğŸ“‹ Kommandoreferens

| Kommando | Beskrivning | Antal profiler |
|----------|-------------|----------------|
| `url_test` | Snabb test | 5 |
| `url_sample` | Medelstor test | 100 |
| `url_run` | Full scraping | 6,360 |
| `url_debug` | Debug-lÃ¤ge | 1 |

## ğŸ¯ Rekommendationer

1. **BÃ¶rja med `url_test`** fÃ¶r att verifiera att allt fungerar
2. **AnvÃ¤nd `url_sample`** fÃ¶r att testa prestanda
3. **KÃ¶r `url_run`** endast nÃ¤r du Ã¤r sÃ¤ker pÃ¥ konfigurationen
4. **Ã–vervaka med `logs`** under lÃ¤ngre kÃ¶rningar

## ğŸ” FelsÃ¶kning

### Om profile_urls.txt saknas:
```bash
# Kontrollera att filen finns
ls -la profile_urls.txt

# Kopiera frÃ¥n backup om nÃ¶dvÃ¤ndigt
cp backup/profile_urls.txt .
```

### Om 403-fel kvarstÃ¥r:
1. Ã–ka delay: `-s DOWNLOAD_DELAY=15`
2. AnvÃ¤nd proxy: LÃ¤gg till proxy-konfiguration
3. Kontrollera IP-status: KÃ¶r IP-test

### Om inga bilder hittas:
- Kontrollera image-selektorer i spider
- Verifiera att mÃ¥lsidorna har bilder
- Kontrollera nÃ¤tverksanslutning

## ğŸ“Š FÃ¶rvÃ¤ntade Resultat

Med denna metod bÃ¶r du fÃ¥:
- **200 OK** istÃ¤llet fÃ¶r 403 Forbidden
- **FramgÃ¥ngsrik bildnedladdning** frÃ¥n profiler
- **Minimal risk fÃ¶r blockering** (distribuerade requests)
- **HÃ¶g success rate** (>90% av profiler)

## ğŸ‰ Slutsats

URL-baserade scrapern lÃ¶ser det ursprungliga 403-problemet genom att helt undvika den blockerade huvudsidan. Kombinerat med det avancerade anti-blocking-systemet ger detta en robust och effektiv scraping-lÃ¶sning.

