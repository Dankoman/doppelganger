#!/bin/bash

# Doppelganger Scraper - Enhanced Anti-Blocking Edition
# Hanteringsscript fÃ¶r Docker-baserad scraping

set -e

# FÃ¤rger fÃ¶r output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Banner
show_banner() {
    echo -e "${BLUE}"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                      ğŸ•·ï¸  Doppelganger Scraper v2.0                          â•‘"
    echo "â•‘                    Enhanced Anti-Blocking Edition                            â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}"
}

# Kontrollera att Docker kÃ¶rs
check_docker() {
    if ! docker info >/dev/null 2>&1; then
        echo -e "${RED}âŒ Docker kÃ¶rs inte. Starta Docker fÃ¶rst.${NC}"
        exit 1
    fi
}

# Skapa nÃ¶dvÃ¤ndiga kataloger
ensure_directories() {
    mkdir -p images crawls logs httpcache
    chmod 755 images crawls logs httpcache
}

# URL-baserade scraper-funktioner
url_test() {
    show_banner
    echo -e "${YELLOW}ğŸ§ª Testar URL-baserad scraper med 5 profiler...${NC}"
    check_docker
    ensure_directories
    
    # Kontrollera att URL-filen finns
    if [ ! -f "profile_urls.txt" ]; then
        echo -e "${RED}âŒ profile_urls.txt saknas. Kopiera filen frÃ¥n HTML-extraktionen.${NC}"
        exit 1
    fi
    
    echo -e "${CYAN}ğŸ“Š Antal URL:er i fil: $(wc -l < profile_urls.txt)${NC}"
    
    # KÃ¶r test med URL-baserad spider
    docker-compose run --rm doppelganger-scraper scrapy crawl mpb_from_urls \
        -s CLOSESPIDER_ITEMCOUNT=5 \
        -s LOG_LEVEL=INFO
}

url_run() {
    show_banner
    echo -e "${YELLOW}ğŸš€ KÃ¶r URL-baserad scraper fÃ¶r alla profiler...${NC}"
    check_docker
    ensure_directories
    
    # Kontrollera att URL-filen finns
    if [ ! -f "profile_urls.txt" ]; then
        echo -e "${RED}âŒ profile_urls.txt saknas. Kopiera filen frÃ¥n HTML-extraktionen.${NC}"
        exit 1
    fi
    
    echo -e "${CYAN}ğŸ“Š Antal URL:er att scrapa: $(wc -l < profile_urls.txt)${NC}"
    echo -e "${YELLOW}âš ï¸  Detta kommer att scrapa ALLA profiler. FortsÃ¤tt? (y/N):${NC}"
    read -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        # KÃ¶r full URL-baserad scraping
        docker-compose run --rm doppelganger-scraper scrapy crawl mpb_from_urls \
            -s LOG_LEVEL=INFO
    else
        echo -e "${CYAN}â„¹ï¸  Scraping avbruten${NC}"
    fi
}

url_sample() {
    show_banner
    echo -e "${YELLOW}ğŸ“Š KÃ¶r URL-baserad scraper fÃ¶r 100 profiler...${NC}"
    check_docker
    ensure_directories
    
    # Kontrollera att URL-filen finns
    if [ ! -f "profile_urls.txt" ]; then
        echo -e "${RED}âŒ profile_urls.txt saknas. Kopiera filen frÃ¥n HTML-extraktionen.${NC}"
        exit 1
    fi
    
    echo -e "${CYAN}ğŸ“Š Antal URL:er i fil: $(wc -l < profile_urls.txt)${NC}"
    
    # KÃ¶r sample med URL-baserad spider
    docker-compose run --rm doppelganger-scraper scrapy crawl mpb_from_urls \
        -s CLOSESPIDER_ITEMCOUNT=100 \
        -s LOG_LEVEL=INFO
}

url_debug() {
    show_banner
    echo -e "${YELLOW}ğŸ› Debug URL-baserad scraper...${NC}"
    check_docker
    ensure_directories
    
    # Kontrollera att URL-filen finns
    if [ ! -f "profile_urls.txt" ]; then
        echo -e "${RED}âŒ profile_urls.txt saknas. Kopiera filen frÃ¥n HTML-extraktionen.${NC}"
        exit 1
    fi
    
    echo -e "${CYAN}ğŸ“Š FÃ¶rsta 5 URL:er:${NC}"
    head -5 profile_urls.txt
    echo ""
    
    # KÃ¶r debug med URL-baserad spider
    docker-compose run --rm doppelganger-scraper scrapy crawl mpb_from_urls \
        -L DEBUG \
        -s CLOSESPIDER_ITEMCOUNT=1 \
        -s DOWNLOAD_DELAY=10 \
        -s CONCURRENT_REQUESTS=1
}

# HjÃ¤lpfunktioner
show_help() {
    show_banner
    echo -e "${YELLOW}AnvÃ¤ndning:${NC} $0 [KOMMANDO]"
    echo ""
    echo -e "${CYAN}TillgÃ¤ngliga kommandon:${NC}"
    echo ""
    echo -e "  ${GREEN}build${NC}           Bygg Docker-imagen med alla fÃ¶rbÃ¤ttringar"
    echo -e "  ${GREEN}test${NC}            KÃ¶r test med begrÃ¤nsad scraping (5 items)"
    echo -e "  ${GREEN}run${NC}             KÃ¶r full scraping (interaktivt)"
    echo -e "  ${GREEN}run-detached${NC}    KÃ¶r full scraping i bakgrunden"
    echo -e "  ${GREEN}stop${NC}            Stoppa alla kÃ¶rande containers"
    echo -e "  ${GREEN}logs${NC}            Visa live loggar frÃ¥n scrapern"
    echo -e "  ${GREEN}shell${NC}           Ã–ppna bash-shell i container"
    echo -e "  ${GREEN}status${NC}          Visa status fÃ¶r containers"
    echo -e "  ${GREEN}clean${NC}           Rensa alla containers och volymer"
    echo -e "  ${GREEN}monitor${NC}        Starta monitoring-interface (port 8080)"
    echo -e "  ${GREEN}verify${NC}         Verifiera Brotli och andra fÃ¶rbÃ¤ttringar"
    echo -e "  ${GREEN}debug${NC}          KÃ¶r i debug-lÃ¤ge med detaljerade loggar"
    echo ""
    echo -e "${CYAN}URL-baserade kommandon (kringgÃ¥r blockerad huvudsida):${NC}"
    echo -e "  ${GREEN}url_test${NC}       Testa URL-baserad scraper (5 profiler)"
    echo -e "  ${GREEN}url_sample${NC}     Scrapa 100 profiler frÃ¥n URL-lista"
    echo -e "  ${GREEN}url_run${NC}        Scrapa alla profiler frÃ¥n URL-lista"
    echo -e "  ${GREEN}url_debug${NC}      Debug URL-baserad scraper"
    echo ""
    echo -e "${YELLOW}Exempel:${NC}"
    echo -e "  $0 build && $0 test     ${PURPLE}# Bygg och testa${NC}"
    echo -e "  $0 url_test             ${PURPLE}# Testa URL-scraper${NC}"
    echo -e "  $0 url_sample           ${PURPLE}# Scrapa 100 profiler${NC}"
    echo -e "  $0 logs                 ${PURPLE}# Ã–vervaka framsteg${NC}"
    echo ""
    echo -e "${CYAN}FÃ¶rbÃ¤ttringar i v2.0:${NC}"
    echo -e "  âœ… Brotli-komprimeringssstÃ¶d"
    echo -e "  âœ… 12 realistiska User Agents"
    echo -e "  âœ… Avancerade anti-blocking headers"
    echo -e "  âœ… Adaptiv fÃ¶rdrÃ¶jning vid 403-fel"
    echo -e "  âœ… Exponential backoff retry-logik"
    echo -e "  âœ… URL-baserad scraping (kringgÃ¥r blockering)"
    echo ""
}

# Huvudfunktioner
case "${1:-help}" in
    "build")
        show_banner
        echo -e "${YELLOW}ğŸ”¨ Bygger Docker-imagen med Enhanced Anti-Blocking...${NC}"
        check_docker
        ensure_directories
        
        # Bygg imagen
        docker-compose build --no-cache
        
        echo -e "${GREEN}âœ… Docker-imagen byggd framgÃ¥ngsrikt!${NC}"
        echo -e "${CYAN}ğŸ’¡ Testa nu med: $0 test eller $0 url_test${NC}"
        ;;
        
    "test")
        show_banner
        echo -e "${YELLOW}ğŸ§ª KÃ¶r test med begrÃ¤nsad scraping...${NC}"
        check_docker
        ensure_directories
        
        # KÃ¶r test med begrÃ¤nsning
        docker-compose run --rm doppelganger-scraper scrapy crawl mpb_all \
            -s CLOSESPIDER_ITEMCOUNT=5 \
            -s DOWNLOAD_DELAY=5 \
            -s CONCURRENT_REQUESTS=1 \
            -L INFO
        ;;
        
    "run")
        show_banner
        echo -e "${YELLOW}ğŸš€ KÃ¶r full scraping (interaktivt)...${NC}"
        check_docker
        ensure_directories
        
        # KÃ¶r full scraping
        docker-compose run --rm doppelganger-scraper scrapy crawl mpb_all
        ;;
        
    "run-detached")
        show_banner
        echo -e "${YELLOW}ğŸš€ KÃ¶r full scraping i bakgrunden...${NC}"
        check_docker
        ensure_directories
        
        # KÃ¶r i bakgrunden
        docker-compose up -d doppelganger-scraper
        echo -e "${GREEN}âœ… Scraper startad i bakgrunden${NC}"
        echo -e "${CYAN}ğŸ’¡ Visa loggar med: $0 logs${NC}"
        echo -e "${CYAN}ğŸ’¡ Stoppa med: $0 stop${NC}"
        ;;
        
    "stop")
        show_banner
        echo -e "${YELLOW}ğŸ›‘ Stoppar alla containers...${NC}"
        check_docker
        
        docker-compose down
        echo -e "${GREEN}âœ… Alla containers stoppade${NC}"
        ;;
        
    "logs")
        show_banner
        echo -e "${YELLOW}ğŸ“‹ Visar live loggar (Ctrl+C fÃ¶r att avsluta)...${NC}"
        check_docker
        
        docker-compose logs -f doppelganger-scraper
        ;;
        
    "shell")
        show_banner
        echo -e "${YELLOW}ğŸš Ã–ppnar bash-shell i container...${NC}"
        check_docker
        
        docker-compose run --rm doppelganger-scraper bash
        ;;
        
    "status")
        show_banner
        echo -e "${YELLOW}ğŸ“Š Container-status:${NC}"
        check_docker
        
        docker-compose ps
        echo ""
        echo -e "${YELLOW}ğŸ“ˆ Docker-statistik:${NC}"
        docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"
        ;;
        
    "clean")
        show_banner
        echo -e "${YELLOW}ğŸ§¹ Rensar containers och volymer...${NC}"
        check_docker
        
        read -p "âš ï¸  Detta kommer att ta bort alla containers och data. FortsÃ¤tt? (y/N): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            docker-compose down -v
            docker system prune -f
            echo -e "${GREEN}âœ… Rensning klar${NC}"
        else
            echo -e "${CYAN}â„¹ï¸  Rensning avbruten${NC}"
        fi
        ;;
        
    "monitor")
        show_banner
        echo -e "${YELLOW}ğŸ“Š Startar monitoring-interface...${NC}"
        check_docker
        ensure_directories
        
        # Starta monitoring
        docker-compose --profile monitoring up -d scraper-monitor
        echo -e "${GREEN}âœ… Monitoring startat pÃ¥ http://localhost:8080${NC}"
        echo -e "${CYAN}ğŸ’¡ Stoppa med: docker-compose --profile monitoring down${NC}"
        ;;
        
    "verify")
        show_banner
        echo -e "${YELLOW}ğŸ” Verifierar fÃ¶rbÃ¤ttringar...${NC}"
        check_docker
        
        echo -e "${CYAN}Testar Brotli-stÃ¶d:${NC}"
        docker-compose run --rm doppelganger-scraper python -c "
import brotli, brotlicffi
print('âœ… Brotli support: OK')
print(f'   brotli version: {brotli.__version__}')
print(f'   brotlicffi version: {brotlicffi.__version__}')
"
        
        echo -e "${CYAN}Testar komprimering:${NC}"
        docker-compose run --rm doppelganger-scraper python -c "
import brotli
data = b'Hello Enhanced Doppelganger!'
compressed = brotli.compress(data)
decompressed = brotli.decompress(compressed)
print(f'âœ… Compression test: {decompressed.decode()}')
print(f'   Original size: {len(data)} bytes')
print(f'   Compressed size: {len(compressed)} bytes')
print(f'   Compression ratio: {len(compressed)/len(data):.2%}')
"
        
        echo -e "${CYAN}Testar Scrapy-konfiguration:${NC}"
        docker-compose run --rm doppelganger-scraper python -c "
from scrapy.utils.project import get_project_settings
settings = get_project_settings()
print('âœ… Scrapy settings loaded')
print(f'   Download delay: {settings.get(\"DOWNLOAD_DELAY\")}s')
print(f'   Concurrent requests: {settings.get(\"CONCURRENT_REQUESTS\")}')
print(f'   Anti-blocking enabled: {settings.get(\"ANTIBLOCK_ENABLED\")}')
print(f'   Retry times: {settings.get(\"RETRY_TIMES\")}')
"
        
        echo -e "${GREEN}âœ… Alla verifieringar klara!${NC}"
        ;;
        
    "debug")
        show_banner
        echo -e "${YELLOW}ğŸ› KÃ¶r i debug-lÃ¤ge...${NC}"
        check_docker
        ensure_directories
        
        # KÃ¶r med debug och begrÃ¤nsning
        docker-compose run --rm doppelganger-scraper scrapy crawl mpb_all \
            -L DEBUG \
            -s CLOSESPIDER_ITEMCOUNT=1 \
            -s DOWNLOAD_DELAY=10 \
            -s CONCURRENT_REQUESTS=1
        ;;
        
    "url_test")
        url_test
        ;;
        
    "url_run")
        url_run
        ;;
        
    "url_sample")
        url_sample
        ;;
        
    "url_debug")
        url_debug
        ;;
        
    "help"|*)
        show_help
        ;;
esac
